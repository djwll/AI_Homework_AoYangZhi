{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "# 监督学习 - 双相障碍检测\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "# 1. 实验介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "## 1.1 实验背景\n",
    "\n",
    "双相障碍属于心境障碍的一种疾病，英文名称为 Bipolar Disorder（BD），别名为 Bipolar Affective Disorder，表示既有躁狂发作又有抑郁发作的一类疾病。\n",
    "\n",
    "目前病因未明，主要是生物、心理与社会环境诸多方面因素参与其发病过程。\n",
    "\n",
    "当前研究发现，在双相障碍发生过程中遗传因素、环境或应激因素之间的交互作用、以及交互作用的出现时间点等都产生重要的影响；临床表现按照发作特点可以分为抑郁发作、躁狂发作或混合发作。\n",
    "\n",
    "双相障碍检测，即通过医学检测数据预测病人是否双相障碍，或双相障碍治疗是否有效。\n",
    "\n",
    "医学数据包括医学影像数据与肠道数据。\n",
    "\n",
    "由于缺少医学样本且特征过多，因此选取合适的特征对双模态特征进行整合并训练合适的分类器进行模型预测具有较强的现实需求与医学意义。\n",
    "\n",
    "本实验需要大家完成少样本、多特征下的监督学习。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "## 1.2 实验要求\n",
    "\n",
    "a) 实现双模态特征选择与提取整合。\n",
    "\n",
    "b) 选择并训练机器学习模型进行准确分类。\n",
    "\n",
    "c) 分析不同超参数以及特征选择方法对模型的结果影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "## 1.3 实验环境\n",
    "\n",
    "可以使用 Numpy 库进行相关数值运算，使用 sklearn 库进行特征选择和训练机器学习模型等。\n",
    "\n",
    "## 1.4 注意事项\n",
    "+ Python 与 Python Package 的使用方式，可在右侧 `API文档` 中查阅。\n",
    "+ 当右上角的『Python 3』长时间指示为运行中的时候，造成代码无法执行时，可以重新启动 Kernel 解决（左上角『Kernel』-『Restart Kernel』）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "## 1.5 参考资料\n",
    "\n",
    "Numpy：https://www.numpy.org/\n",
    "\n",
    "Scikit-learn： https://scikit-learn.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "# 2.实验内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "\n",
    "## 2.1 导入数据\n",
    "\n",
    "医疗数据集存放在左侧栏中的 `DataSet.xlsx` 中，共包括 39 个样本和 3 张表，表 `Feature1` 为医学影像特征，表 `Feature2` 为肠道特征，表 `label` 为样本类标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\word\\summer_winter_2023\\人工智能与机器学习\\Important_Team_Homework\\双目检测\\main.ipynb 单元格 9\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/word/summer_winter_2023/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Important_Team_Homework/%E5%8F%8C%E7%9B%AE%E6%A3%80%E6%B5%8B/main.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mitertools\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/word/summer_winter_2023/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Important_Team_Homework/%E5%8F%8C%E7%9B%AE%E6%A3%80%E6%B5%8B/main.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/word/summer_winter_2023/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Important_Team_Homework/%E5%8F%8C%E7%9B%AE%E6%A3%80%E6%B5%8B/main.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/word/summer_winter_2023/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Important_Team_Homework/%E5%8F%8C%E7%9B%AE%E6%A3%80%E6%B5%8B/main.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/word/summer_winter_2023/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Important_Team_Homework/%E5%8F%8C%E7%9B%AE%E6%A3%80%E6%B5%8B/main.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtime\u001b[39;00m \u001b[39mimport\u001b[39;00m time\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# 导入相关库\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "from minepy import MINE\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import naive_bayes\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.manifold import TSNE\n",
    "from IPython.display import display\n",
    "from datetime import datetime as dt\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入医疗数据\n",
    "data_xls = pd.ExcelFile('DataSet.xlsx')\n",
    "data={}\n",
    "\n",
    "#查看数据名称与大小\n",
    "for name in data_xls.sheet_names:\n",
    "    df = data_xls.parse(sheet_name=name,header=None)\n",
    "    print(\"%-8s 表的 shape:\"%name,df.shape)\n",
    "    data[name] = df\n",
    "    \n",
    "#获取 特征1 特征2 类标    \n",
    "feature1_raw = data['Feature1']\n",
    "feature2_raw = data['Feature2']\n",
    "label = data['label']\n",
    "\n",
    "#显示第一条样本数据\n",
    "display(feature1_raw.head(n=1))\n",
    "display(feature2_raw.head(n=1))\n",
    "display(label.head(n=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "可以看到，医疗数据中的样本和特征数量存在着极大的不平衡。\n",
    "\n",
    "其中医疗影像数据共 6670 维，肠道数据共 377 维，而样本仅有 39 个，其中正样本标签为 1 ，负样本标签为 -1 。\n",
    "\n",
    "因此，特征的筛选和组合以及机器学习模型的选择优化对提高模型的性能极其重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "## 2.2 准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "**数据预处理** 是一种数据挖掘技术，它是指把原始数据转换成可以理解的格式。在这个过程中一般有数据清洗、数据变换、数据组织、数据降维和格式化等操作。\n",
    "\n",
    "对于本数据集，没有无效或丢失的条目；然而需要我们进行特征的筛选和整合。\n",
    "\n",
    "我们可以针对某一些特征存在的特性进行一定的调整。\n",
    "\n",
    "这些预处理可以极大地帮助我们提升机器学习算法模型的性能和预测能力。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "**归一化数字特征**\n",
    "\n",
    "对数值特征施加一些形式的缩放，可以减少量纲对数据的影响。\n",
    "\n",
    "对数据分析发现，`Feature2` 中的特征值存在较大差异，比如第 0 维和第 374 维；大家可以试试观察其它列特征是否有这种现象？\n",
    "\n",
    "数据归一化的作用:                     \n",
    "１）把数据变成 (０,１) 或者（-1,1）之间的小数。主要是为了数据处理方便提出来的，把数据映射到 0～1 范围之内处理，更加便捷快速。                                         \n",
    "２）把有量纲表达式变成无量纲表达式，便于不同单位或量级的指标能够进行比较和加权。\n",
    "             \n",
    "注意：一旦使用了缩放，观察数据的原始形式不再具有它本来的意义了。\n",
    "\n",
    "我们将使用 [`sklearn.preprocessing.MinMaxScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) 来完成这个任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def processing_data(data_path):\n",
    "    \"\"\"\n",
    "    数据处理\n",
    "    :param data_path: 数据集路径\n",
    "    :return: feature1,feature2,label: 处理后的特征数据、标签数据\n",
    "    \"\"\"\n",
    "    \n",
    "    #导入医疗数据\n",
    "    data_xls = pd.ExcelFile(data_path)\n",
    "    data={}\n",
    "    \n",
    "    #查看数据名称与大小\n",
    "    for name in data_xls.sheet_names:\n",
    "            df = data_xls.parse(sheet_name=name,header=None)\n",
    "            data[name] = df\n",
    "    \n",
    "    #获取 特征1 特征2 类标    \n",
    "    feature1_raw = data['Feature1']\n",
    "    feature2_raw = data['Feature2']\n",
    "    label = data['label']\n",
    "\n",
    "\n",
    "    # 初始化一个 scaler，并将它施加到特征上\n",
    "    scaler = MinMaxScaler()\n",
    "    feature1 = pd.DataFrame(scaler.fit_transform(feature1_raw))\n",
    "    feature2 = pd.DataFrame(scaler.fit_transform(feature2_raw))\n",
    "\n",
    "    return feature1,feature2,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据路径\n",
    "data_path = \"DataSet.xlsx\"\n",
    "\n",
    "#获取处理后的特征数据和类标数据\n",
    "feature1,feature2,label = processing_data(data_path)\n",
    "\n",
    "# 显示一个经过缩放的样例记录\n",
    "display(feature1.head(n = 1))\n",
    "display(feature2.head(n = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "## 2.3 评价模型性能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "我们的研究目的，是通过医学检测数据预测病人是否双相障碍，或双相障碍治疗是否有效。                           \n",
    "因此，对于准确预测病人是否双相障碍，或双相障碍治疗是否有效是问题的关键。                           \n",
    "这样看起来使用**准确率**作为评价模型的标准是合适的。                \n",
    "\n",
    "我们将算法预测结果分为四种情况：\n",
    "\n",
    "<center><img src=\"https://imgbed.momodel.cn/20200819172058.png\" width=600/><center>\n",
    "    \n",
    "<br>\n",
    "    \n",
    "**准确率（Accuracy）**是指分类正确的样本占总样本个数的比例\n",
    "$$accuracy = \\frac{预测正确的样本数}{总样本数} = \\frac{TP+TN}{TP+TN+FP+FN}$$\n",
    "    \n",
    "但是，把双相障碍的病人预测为正常人，或者把治疗无效预测为有效是存在极大的医学隐患的。        \n",
    "我们期望的模型具有能够 **查全** 所有双相障碍病人或者双相治疗有效法人病例与模型的准确预测**同样重要**。               \n",
    "因此，我们使用 **查全率（Recall）** 作为评价模型的另一标准。\n",
    "    \n",
    "**查准率（Precision）**在算法预测都为正类（Positive）样本中，实际是正类（Positive）样本的比例\n",
    "$$precision = \\frac{TP}{TP+FP}$$ \n",
    "    \n",
    "**查全率（Recall）** 在实际值是正类（Positive）的样本中，算法预测是正类样本的比例\n",
    "$$recall=\\frac{TP}{TP+FN}$$\n",
    "我们使用 **F-beta score** 作为评价指标，这样能够同时考虑查准率和查全率：\n",
    "\n",
    "$$ F_{\\beta} = (1 + \\beta^2) \\cdot \\frac{precision \\cdot recall}{\\left( \\beta^2 \\cdot precision \\right) + recall} $$\n",
    "\n",
    "当 $\\beta = 1$ 时，就是我们常听说的 **F1 值（F1 score）**                \n",
    "当 $\\beta = 0.5$ 的时候更多的强调查准率，这叫做 **F$_{0.5}$ score** （或者为了简单叫做 F-score）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "toc-hr-collapsed": false
   },
   "source": [
    "## 2.4 特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "使用监督学习算法的一个重要的任务是决定哪些数据特征能够提供最强的预测能力。                     \n",
    "专注于少量的有效特征和标签之间的关系，我们能够更加简单具体地理解标签与特征之间的关系，这在很多情况下都是十分有用的。\n",
    "\n",
    "可以看到：医疗数据中的样本和特征数量存在着极大的不平衡，其中医疗影像数据共 6670 维，肠道数据共 377 维，而样本仅有 39 个。\n",
    "\n",
    "因此，为了训练预测模型，特征的筛选和组合以及机器学习模型的选择优化极其重要。\n",
    "\n",
    "同时，在这个项目的情境下选择一小部分特征，也具有很大的医学意义。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "### 2.4.1 常见的特征选择方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对 feature1 和 feature2 进行整合\n",
    "features = pd.concat([feature1,feature2],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "（1）**feature_importance 排序**\n",
    "\n",
    "选择一个有 `feature_importance_` 属性的机器学习分类器（例如决策树、AdaBoost、随机森林）或者 sklearn 中的统计函数对特征进行计算筛选。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入一个有 feature_importances_ 的监督学习模型\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(features,label)\n",
    "\n",
    "# 提取特征重要性\n",
    "importances = clf.feature_importances_\n",
    "\n",
    "# 需要提取的特征\n",
    "# 定义特征数量并根据重要性排序 获得特征序号\n",
    "select_feature_number = 5\n",
    "select_features = (np.argsort(importances)[::-1])[:select_feature_number]\n",
    "\n",
    "# 查看提取的特征序号\n",
    "print(select_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "（2）**相关性系数选择**\n",
    "\n",
    "使用 `sklearn` 中的统计函数对特征进行计算筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入需要的库\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from scipy.stats import pearsonr\n",
    "from minepy import MINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "计算各个特征与标签的相关系数，常用的指标就是皮尔逊相关系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SelectKBest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_66/3747013313.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 统计特征值和 label 的皮尔孙相关系数  进行排序筛选特征\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mselect_feature_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m select_features = SelectKBest(lambda X, Y: tuple(map(tuple,np.array(list(map(lambda x:pearsonr(x, Y), X.T))).T)), \n\u001b[0m\u001b[1;32m      4\u001b[0m                               \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselect_feature_number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                              ).fit(features, np.array(label).flatten()).get_support(indices=True)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SelectKBest' is not defined"
     ]
    }
   ],
   "source": [
    "# 统计特征值和 label 的皮尔孙相关系数  进行排序筛选特征\n",
    "select_feature_number = 10\n",
    "select_features = SelectKBest(lambda X, Y: tuple(map(tuple,np.array(list(map(lambda x:pearsonr(x, Y), X.T))).T)), \n",
    "                              k=select_feature_number\n",
    "                             ).fit(features, np.array(label).flatten()).get_support(indices=True)\n",
    "\n",
    "# 查看提取的特征序号\n",
    "print(select_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "（3）**卡方检验**\n",
    "\n",
    "卡方检验就是统计样本的实际观测值与理论推断值之间的偏离程度。                       \n",
    "实际观测值与理论推断值之间的偏离程度就决定卡方值的大小；                \n",
    "如果卡方值越大，二者偏差程度越大；反之，二者偏差越小；若两个值完全相等时，卡方值就为0，表明理论值完全符合。                      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卡方检验 筛选特征\n",
    "select_feature_number = 10\n",
    "select_features = SelectKBest(chi2, \n",
    "                              k=select_feature_number\n",
    "                             ).fit(features, np.array(label).flatten()).get_support(indices=True)\n",
    "\n",
    "# 查看提取的特征序号\n",
    "print(select_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "（4）**互信息法**\n",
    "\n",
    "互信息法也是用来评定类别自变量对类别因变量的相关性的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 互信息法 筛选特征\n",
    "# 由于 MINE 的设计不是函数式的，定义 mic 方法将其为函数式的，返回一个二元组，二元组的第 2 项设置成固定的 P 值 0.5\n",
    "def mic(x, y):\n",
    "      m = MINE()\n",
    "      m.compute_score(x, y)\n",
    "      return (m.mic(), 0.5)\n",
    "\n",
    "select_feature_number = 5  \n",
    "select_features = SelectKBest(lambda X, Y: tuple(map(tuple,np.array(list(map(lambda x:mic(x, Y), X.T))).T)), \n",
    "                              k=select_feature_number\n",
    "                             ).fit(features, np.array(label).flatten()).get_support(indices=True)\n",
    "\n",
    "# 查看提取的特征序号\n",
    "print(select_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "（5）**特征降维之 t-SNE**\n",
    "\n",
    "所谓的降维就是指采用某种映射方法，将原高维空间中的数据点映射到低维度的空间中去。                  \n",
    "由于数据降维是函数映射，因此，不同于特征筛选，特征降维会改变的特征值，会丢失一定的特征信息。                   \n",
    "但这也有助于我们对特征进行低维观察和可视化，以选择进一步的筛选操作。                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入需要的库\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "TSNE 是由 T 和 SNE 组成，也就是 T 分布和随机近邻嵌入（Stochastic neighbour Embedding ），简单来说，TSNE 就是一种数据可视化的工具，能够将高维数据降到 2-3 维，然后将特征值绘制在平面图或者三维空间上，便于观察数据分布情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择降维维度\n",
    "tsne = TSNE(n_components=2)\n",
    "feature_tsne = tsne.fit_transform(features)\n",
    "\n",
    "# 可视化类标中不能出现负值\n",
    "tsne_label = np.array(label).flatten()\n",
    "\n",
    "# 可视化\n",
    "plt.scatter(feature_tsne[:, 0], feature_tsne[:, 1], c=tsne_label)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "（6）**特征降维之主成分分析算法 PCA**\n",
    "\n",
    "Principal Component Analysis(PCA) 是最常用的线性降维方法，它的目标是通过某种线性投影，将高维的数据映射到低维的空间中表示，并期望在所投影的维度上数据的方差最大，以此使用较少的数据维度，同时保留住较多的原数据的特性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择降维维度\n",
    "pca = PCA(n_components=2)\n",
    "feature_pca = pca.fit_transform(features)\n",
    "\n",
    "# 可视化标签中不能出现负值\n",
    "pca_label = np.array(label).flatten()\n",
    "\n",
    "# 可视化\n",
    "plt.scatter(feature_pca[:, 0], feature_pca[:, 1], c=pca_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "（7）**双模态特征选择和融合**\n",
    "\n",
    "以上特征选择都是在将医疗影像数据和肠道数据直接拼接后进行的。         \n",
    "但是事实上，双模态特征各自具有不同的分布和医学意义，因此，分别对各特征进行筛选，再按照相关算法进行特征的融合是比较合理的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计特征值和label的皮尔孙相关系数  对两类特征分别进行排序筛选特征\n",
    "select_feature_number = 5\n",
    "select_feature1 = SelectKBest(lambda X, Y: tuple(map(tuple,np.array(list(map(lambda x:pearsonr(x, Y), X.T))).T)), \n",
    "                              k=select_feature_number\n",
    "                             ).fit(feature1, np.array(label).flatten()).get_support(indices=True)\n",
    "\n",
    "select_feature2 = SelectKBest(lambda X, Y: tuple(map(tuple,np.array(list(map(lambda x:pearsonr(x, Y), X.T))).T)), \n",
    "                              k=select_feature_number\n",
    "                             ).fit(feature2, np.array(label).flatten()).get_support(indices=True)\n",
    "\n",
    "# 查看排序后特征\n",
    "print(\"select feature1 name:\", select_feature1)\n",
    "print(\"select feature2 name:\", select_feature2)\n",
    "\n",
    "# 双模态特征选择并融合\n",
    "new_features = pd.concat([feature1[feature1.columns.values[select_feature1]],\n",
    "                          feature2[feature2.columns.values[select_feature2]]],axis=1)\n",
    "print(\"new_features shape:\",new_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "### 2.4.2 进行特征选择\n",
    "\n",
    "定义 `feature_select` 函数进行特征选择\n",
    "\n",
    "以皮尔逊相关系数为例，进行特征选择并得到新特征数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_select(feature1, feature2, label):\n",
    "    \"\"\"\n",
    "    特征选择\n",
    "    :param  feature1,feature2,label: 数据处理后的输入特征数据、标签数据\n",
    "    :return: new_features,label:特征选择后的特征数据、标签数据\n",
    "    \"\"\"\n",
    "\n",
    "    # 整合特征\n",
    "    features = pd.concat([feature1, feature2], axis=1)\n",
    "\n",
    "    # 统计特征值和label的皮尔孙相关系数  进行排序筛选特征\n",
    "    select_feature_number = 12\n",
    "    select_features = SelectKBest(lambda X, Y: tuple(map(tuple, np.array(list(map(lambda x: pearsonr(x, Y), X.T))).T)),\n",
    "                                  k=select_feature_number).fit(features,np.array(label).flatten()).get_support(indices=True)\n",
    "\n",
    "    # 查看提取的特征序号\n",
    "    print(\"查看提取的特征序号:\", select_features)\n",
    "\n",
    "    # 特征选择\n",
    "    new_features = features[features.columns.values[select_features]]\n",
    "\n",
    "    # 返回筛选后的数据\n",
    "    return new_features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看特征选择结果\n",
    "new_features,label=feature_select(feature1, feature2, label)\n",
    "print(\"特征 shape: \", new_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "### 2.4.3 混洗和切分数据\n",
    "\n",
    "现在特征选择已经完成并得到了新的特征数据。                                         \n",
    "那么下面将数据（包括特征和它们的标签）整合并切分成训练集和测试集。                             \n",
    "其中 80% 的数据将用于训练和 20% 的数据用于测试。                      \n",
    "然后再进一步把训练数据分为训练集和验证集，用来选择和优化模型。                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def data_split(features, label):\n",
    "    \"\"\"\n",
    "    数据切分\n",
    "    :param features: 特征选择后的输入特征数据\n",
    "    :param label: 标签数据\n",
    "    :return: X_train:数据切分后的训练数据\n",
    "             X_val:数据切分后的验证数据\n",
    "             X_test:数据切分后的测试数据\n",
    "             y_train:数据切分后的训练数据标签\n",
    "             y_val:数据切分后的验证数据标签\n",
    "             y_test:数据切分后的测试数据标签\n",
    "    \"\"\"\n",
    "    # 将 features 和 label 数据切分成训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.2, random_state=0, stratify=label)\n",
    "\n",
    "    # 将 X_train 和 y_train 进一步切分为训练集和验证集\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0, stratify=y_train)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行数据切分\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = data_split(new_features, label)\n",
    "\n",
    "# 显示切分的结果\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Validation set has {} samples.\".format(X_val.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "## 2.5 监督学习模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    " [`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html) 中的监督学习模型包括：\n",
    "- 高斯朴素贝叶斯 (GaussianNB)\n",
    "- 决策树 (DecisionTree)\n",
    "- 集成方法 (Bagging、 AdaBoost、 Random Forest、 Gradient Boosting)\n",
    "- K 近邻 (K Nearest Neighbors)\n",
    "- 随机梯度下降分类器 (SGDC)\n",
    "- 支持向量机 (SVM)\n",
    "- Logistic 回归（LogisticRegression）\n",
    "\n",
    "\n",
    "\n",
    "从监督学习模型中选择适合我们这个问题的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "为了正确评估你选择的每一个模型的性能，创建一个能够帮助你快速有效地使用训练集并在验证集上做预测的训练和验证的流水线是十分重要的。\n",
    "\n",
    " - 从[`sklearn.metrics`](http://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics)中导入`accuracy_score`，`recall_score`和`fbeta_score`。\n",
    " - 用训练集拟合学习器，并记录训练时间。\n",
    " - 对训练集和验证集进行预测并记录预测时间。\n",
    " - 计算预测训练集的准确率，召回率和 F-score。\n",
    " - 计算预测验证集的准确率，召回率和 F-score。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从sklearn中导入评价指标 - fbeta_score，accuracy_score，recall_score\n",
    "from sklearn.metrics import fbeta_score, accuracy_score, recall_score\n",
    "\n",
    "\n",
    "def train_predict(learner, X_train, y_train, X_val, y_val):\n",
    "    '''\n",
    "    模型训练验证\n",
    "    :param learner: 监督学习模型\n",
    "    :param X_train: 训练集 特征数据\n",
    "    :param y_train: 训练集 类标\n",
    "    :param X_val: 验证集 特征数据\n",
    "    :param y_val: 验证集 类标\n",
    "    :return: results: 训练与验证结果\n",
    "    '''\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # 使用训练集数据来拟合学习器\n",
    "    start = time()  # 获得程序开始时间\n",
    "    learner = learner.fit(X_train, y_train)\n",
    "    end = time()  # 获得程序结束时间\n",
    "\n",
    "    # 计算训练时间\n",
    "    # results['train_time'] = end - start\n",
    "\n",
    "    # 得到在验证集上的预测值\n",
    "    start = time()  # 获得程序开始时间\n",
    "    predictions_val = learner.predict(X_val)\n",
    "    predictions_train = learner.predict(X_train)\n",
    "    end = time()  # 获得程序结束时间\n",
    "\n",
    "    # 计算预测用时\n",
    "    # results['pred_time'] = end - start\n",
    "\n",
    "    # 计算在训练数据的准确率\n",
    "    results['acc_train'] = round(accuracy_score(y_train, predictions_train),4)\n",
    "\n",
    "    # 计算在验证上的准确率\n",
    "    results['acc_val'] = round(accuracy_score(y_val, predictions_val),4)\n",
    "\n",
    "    # 计算在训练数据上的召回率\n",
    "    results['recall_train'] = round(recall_score(y_train, predictions_train),4)\n",
    "\n",
    "    # 计算验证集上的召回率\n",
    "    results['recall_val'] = round(recall_score(y_val, predictions_val),4)\n",
    "\n",
    "    # 计算在训练数据上的F-score\n",
    "    results['f_train'] = round(fbeta_score(y_train, predictions_train, beta=1),4)\n",
    "\n",
    "    # 计算验证集上的F-score\n",
    "    results['f_val'] = round(fbeta_score(y_val, predictions_val, beta=1),4)\n",
    "\n",
    "    # 成功\n",
    "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, len(X_val)))\n",
    "\n",
    "    # 返回结果\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "在下面的代码单元将实现以下功能：             \n",
    "- 导入三个监督学习模型。             \n",
    "- 初始化三个模型并存储在`'clf_A'`，`'clf_B'`和`'clf_C'`中。\n",
    "  - 使用模型的默认参数值，在接下来的部分中将需要对某一个模型的参数进行调整。             \n",
    "  - 设置`random_state`  (如果有这个参数)。       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从sklearn中导入三个监督学习模型\n",
    "from sklearn import tree\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import svm\n",
    "from time import time\n",
    "\n",
    "# 初始化三个模型\n",
    "clf_A = tree.DecisionTreeClassifier(random_state=42)\n",
    "clf_B = naive_bayes.GaussianNB()\n",
    "clf_C = svm.SVC()\n",
    "\n",
    "\n",
    "# 收集学习器的结果\n",
    "results = {}\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    results[clf_name] = train_predict(clf, X_train, y_train, X_val, y_val)\n",
    "\n",
    "    \n",
    "# 打印三个模型得到的训练验证结果\n",
    "print(\"高斯朴素贝叶斯模型结果:\", results['GaussianNB'])\n",
    "print(\"支持向量机模型结果:\", results['SVC'])\n",
    "print(\"决策树模型结果:\", results['DecisionTreeClassifier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "toc-hr-collapsed": false
   },
   "source": [
    "## 2.6 提高效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "我们可以从三个有监督的学习模型中选择 **最好的** 模型。                             \n",
    "你将在整个训练集（`X_train`和`y_train`）上使用网格搜索优化至少调节一个超参数以获得一个比没有调节之前更好的目标结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "调节选择的模型的参数。\n",
    "\n",
    "使用网格搜索（`GridSearchCV`）来至少调整模型的重要参数（至少调整一个），这个参数至少需尝试 3 个不同的值。你要使用整个训练集来完成这个过程。\n",
    "\n",
    "- 导入 [`sklearn.model_selection.GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)  和  [`sklearn.metrics.make_scorer`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html) \n",
    "- 初始化你选择的分类器，并将其存储在 `clf` 中。\n",
    " - 设置 `random_state`  (如果有这个参数)。\n",
    "- 创建一个对于这个模型你希望调整参数的字典。\n",
    " - 例如:  parameters = {'parameter' : [list of values]}。\n",
    " - **注意：** 如果你的学习器有 `max_features` 参数，请不要调节它！\n",
    "- 使用 `make_scorer` 来创建一个 `fbeta_score` 评分对象（设置 $\\beta = 1$）。\n",
    "- 在分类器 clf 上用 `scorer` 作为评价函数运行网格搜索，并将结果存储在 grid_obj 中。\n",
    "- 用训练集（X_train, y_train）训练 grid search object ,并将结果存储在 `grid_fit` 中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "由于训练样本少，因此模型会存在较为严重的过拟合现象。\n",
    "\n",
    "定义函数 `plot_learning_curve` 绘制学习曲线以观察训练过程中的过拟合现象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning_curve(estimator, X, y, cv=None, n_jobs=1):\n",
    "    \"\"\"\n",
    "    绘制学习曲线\n",
    "    :param estimator: 训练好的模型\n",
    "    :param X:绘制图像的 X 轴数据\n",
    "    :param y:绘制图像的 y 轴数据\n",
    "    :param cv: 交叉验证\n",
    "    :param n_jobs:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "    plt.figure('Learning Curve', facecolor='lightgray')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.xlabel('train size')\n",
    "    plt.ylabel('score')\n",
    "    plt.grid(linestyle=\":\")\n",
    "    plt.plot(train_sizes, train_scores_mean, label='traning score')\n",
    "    plt.plot(train_sizes, test_scores_mean, label='val score')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def search_model(X_train, y_train,X_val,y_val, model_save_path):\n",
    "    \"\"\"\n",
    "    创建、训练、优化和保存深度学习模型\n",
    "    :param X_train, y_train: 训练集数据\n",
    "    :param X_val,y_val: 验证集数据\n",
    "    :param save_model_path: 保存模型的路径和名称\n",
    "    \"\"\"\n",
    "\n",
    "    #创建监督学习模型 以决策树为例\n",
    "    clf = tree.DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    # 创建调节的参数列表\n",
    "    parameters = {'max_depth': range(5,10),\n",
    "                  'min_samples_split': range(2,10)}\n",
    "\n",
    "    # 创建一个fbeta_score打分对象 以F-score为例\n",
    "    scorer = make_scorer(fbeta_score, beta=1)\n",
    "\n",
    "    # 在分类器上使用网格搜索，使用'scorer'作为评价函数\n",
    "    kfold = KFold(n_splits=10) #切割成十份\n",
    "\n",
    "    # 同时传入交叉验证函数\n",
    "    grid_obj = GridSearchCV(clf, parameters, scorer, cv=kfold)\n",
    "\n",
    "    #绘制学习曲线\n",
    "    plot_learning_curve(clf, X_train, y_train, cv=kfold, n_jobs=4)\n",
    "\n",
    "    # 用训练数据拟合网格搜索对象并找到最佳参数\n",
    "    grid_obj.fit(X_train, y_train)\n",
    "\n",
    "    # 得到estimator并保存\n",
    "    best_clf = grid_obj.best_estimator_\n",
    "    joblib.dump(best_clf, model_save_path)\n",
    "\n",
    "    # 使用没有调优的模型做预测\n",
    "    predictions = (clf.fit(X_train, y_train)).predict(X_val)\n",
    "    best_predictions = best_clf.predict(X_val)\n",
    "\n",
    "    # 调优后的模型\n",
    "    print (\"best_clf\\n------\")\n",
    "    print (best_clf)\n",
    "\n",
    "    # 汇报调参前和调参后的分数\n",
    "    print(\"\\nUnoptimized model\\n------\")\n",
    "    print(\"Accuracy score on validation data: {:.4f}\".format(accuracy_score(y_val, predictions)))\n",
    "    print(\"Recall score on validation data: {:.4f}\".format(recall_score(y_val, predictions)))\n",
    "    print(\"F-score on validation data: {:.4f}\".format(fbeta_score(y_val, predictions, beta = 1)))\n",
    "    print(\"\\nOptimized Model\\n------\")\n",
    "    print(\"Final accuracy score on the validation data: {:.4f}\".format(accuracy_score(y_val, best_predictions)))\n",
    "    print(\"Recall score on validation data: {:.4f}\".format(recall_score(y_val, best_predictions)))\n",
    "    print(\"Final F-score on the validation data: {:.4f}\".format(fbeta_score(y_val, best_predictions, beta = 1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练，优化模型并保存\n",
    "search_model(X_train, y_train,X_val,y_val, model_save_path='./results/my_model.m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "可以看出优化后的模型，比没有优化的模型好。但是也应该关注模型过拟合的现象问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "对测试数据进行预测，观察模型的性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_model_prediction(X_test,y_test,model_path):\n",
    "    \"\"\"\n",
    "    加载模型和评估模型\n",
    "    :param X_test,y_test: 测试集数据\n",
    "    :param save_model_path: 加载模型的路径和名称,请填写你认为最好的模型\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #加载模型\n",
    "    my_model=joblib.load(model_path)\n",
    "\n",
    "    #对测试数据进行预测\n",
    "    copy_test = [value for value in X_test]\n",
    "    copy_predicts = my_model.predict(X_test)\n",
    "\n",
    "    print (\"Accuracy on test data: {:.4f}\".format(accuracy_score(y_test, copy_predicts)))\n",
    "    print (\"Recall on test data: {:.4f}\".format(recall_score(y_test, copy_predicts)))\n",
    "    print (\"F-score on test data: {:.4f}\".format(fbeta_score(y_test, copy_predicts, beta = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载模型并对测试样本进行测试\n",
    "model_path=\"./results/my_model.m\"\n",
    "load_and_model_prediction(X_test,y_test,model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "# 3. 测试提交"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "通过对以上步骤流程的了解，相信大家对监督学习有了一定的认识。                       \n",
    "但是特征选方法比较简单，模型优化也缺少策略，模型指标准确率、召回率、`F-score` 也不高，模型也存在过拟合等机器学习问题。               \n",
    "大家可以试着写自己的特征选择方法和训练优化自己的监督学习模型，并将其调到最佳状态。                \n",
    "\n",
    "在训练模型等过程中如果需要**保存数据、模型**等请写到  **results**  文件夹。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "## 3.1 训练机器学习模型\n",
    "\n",
    "监督学习模型训练流程, 包含数据处理、特征选择、训练优化模型、模型保存、评价模型等。  \n",
    "如果对训练出来的模型不满意, 你可以通过修改数据处理方法、特征选择方法、调整模型类型和参数等方法重新训练模型, 直至训练出你满意的模型。  \n",
    "如果你对自己训练出来的模型非常满意, 则可以测试提交!  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_data(data_path):\n",
    "   \n",
    "    \"\"\"\n",
    "    数据处理\n",
    "    :param data_path: 数据集路径\n",
    "    :return: feature1,feature2,label:处理后的特征数据、标签数据\n",
    "    \"\"\"\n",
    "    feature1,feature2,label = None, None, None\n",
    "    # -------------------------- 实现数据处理部分代码 ----------------------------\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    \n",
    "    return feature1,feature2,label\n",
    "\n",
    "\n",
    "def feature_select(feature1, feature2, label): \n",
    "    \"\"\"\n",
    "    特征选择\n",
    "    :param  feature1,feature2,label: 数据处理后的输入特征数据，标签数据\n",
    "    :return: new_features,label:特征选择后的特征数据、标签数据\n",
    "    \"\"\" \n",
    "    new_features= None\n",
    "    # -------------------------- 实现特征选择部分代码 ----------------------------\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # 返回筛选后的数据\n",
    "    return new_features,label\n",
    "\n",
    "def data_split(features,labels):\n",
    "\n",
    "    \"\"\"\n",
    "    数据切分\n",
    "    :param  features,label: 特征选择后的输入特征数据、类标数据\n",
    "    :return: X_train, X_val, X_test,y_train, y_val, y_test:数据切分后的训练数据、验证数据、测试数据\n",
    "    \"\"\" \n",
    "    \n",
    "    X_train, X_val, X_test,y_train, y_val, y_test=None, None,None, None, None, None\n",
    "    # -------------------------- 实现数据切分部分代码 ----------------------------\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "\n",
    "    return X_train, X_val, X_test,y_train, y_val, y_test\n",
    "\n",
    "\n",
    "def search_model(X_train, y_train,X_val,y_val, model_save_path):\n",
    "    \"\"\"\n",
    "    创建、训练、优化和保存深度学习模型\n",
    "    :param X_train, y_train: 训练集数据\n",
    "    :param X_val,y_val: 验证集数据\n",
    "    :param save_model_path: 保存模型的路径和名称\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # --------------------- 实现模型创建、训练、优化和保存等部分的代码 ---------------------\n",
    "\n",
    "    # 保存模型（请写好保存模型的路径及名称）\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "def load_and_model_prediction(X_test,y_test,save_model_path):\n",
    "    \"\"\"\n",
    "    加载模型和评估模型\n",
    "    可以实现，比如: 模型优化过程中的参数选择，测试集数据的准确率、召回率、F-score 等评价指标！\n",
    "    主要步骤:\n",
    "        1.加载模型(请填写你训练好的最佳模型),\n",
    "        2.对自己训练的模型进行评估\n",
    "\n",
    "    :param X_test,y_test: 测试集数据\n",
    "    :param save_model_path: 加载模型的路径和名称,请填写你认为最好的模型\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # ----------------------- 实现模型加载和评估等部分的代码 -----------------------\n",
    "\n",
    "    # ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    监督学习模型训练流程, 包含数据处理、特征选择、训练优化模型、模型保存、评价模型等。  \n",
    "    如果对训练出来的模型不满意, 你可以通过修改数据处理方法、特征选择方法、调整模型类型和参数等方法重新训练模型, 直至训练出你满意的模型。  \n",
    "    如果你对自己训练出来的模型非常满意, 则可以进行测试提交! \n",
    "    :return:\n",
    "    \"\"\"\n",
    "    data_path = \"\"  # 数据集路径\n",
    "    \n",
    "    save_model_path = ''  # 保存模型路径和名称\n",
    "\n",
    "    # 获取数据 预处理\n",
    "    feature1,feature2,label = processing_data(data_path)\n",
    "   \n",
    "    #特征选择\n",
    "    new_features,label = feature_select(feature1, feature2, label)\n",
    "   \n",
    "    #数据划分\n",
    "    X_train, X_val, X_test,y_train, y_val, y_test = data_split(new_features,label)\n",
    "    \n",
    "    # 创建、训练和保存模型\n",
    "    search_model(X_train, y_train,X_val,y_val, save_model_path)\n",
    "\n",
    "    # 评估模型\n",
    "    load_and_model_prediction(X_test,y_test,save_model_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "## 3.2 数据处理和特征选择\n",
    "\n",
    "1. 请将你的 `数据处理` 和 `特征选择` 函数进行修改后整合成一个函数 `data_processing_and_feature_selecting()` ，能够对后台的测试数据进行处理和特征选择以便对你的模型进行测试打分。\n",
    "2. 测试数据的格式与你所使用的医疗数据相同，`xlsx`文件，包括多个测试样本， 3 张表，表 `Feature1` 为医学影像特征共 6670 维，表 `Feature2` 为肠道特征共 377 维，表 `label` 为样本类标，正样本为 1 ，负样本为 -1 。\n",
    "3. 在修改 `data_processing_and_feature_selecting()` 函数时请务必注意，直接使用你在平台提供的医疗数据集上的特征排序结果对测试数据进行选择即可，避免对测试数据的二次排序结果和原排序结果不同导致测试结果的偏差。\n",
    "4. 请填写你的模型路径及名称并补充 `predict()` 函数以实现预测。\n",
    "5. 点击左侧栏`提交结果`后点击`生成文件`则需勾选 `data_processing_and_feature_selecting()` 函数和`predict()`函数的 cell，即【**数据处理和特征选择**】和【**数据预测代**】码答题区域的 cell。\n",
    "6. 请导入必要的包和第三方库 (包括此文件中曾经导入过的)。\n",
    "7. 请加载你认为训练最佳的模型，即请按要求填写模型路径。          \n",
    "8. **测试提交时服务端会调用`data_processing_and_feature_selecting()` 函数和 `predict()` 函数，请不要修改该函数的输入输出及其数据类型。**                                  \n",
    "9. 测试提交时记得填写你的模型路径及名称, 如果采用 [离线任务](https://momodel.cn/docs/#/zh-cn/%E5%9C%A8GPU%E6%88%96CPU%E8%B5%84%E6%BA%90%E4%B8%8A%E8%AE%AD%E7%BB%83%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B) 请将模型保存在 **results** 文件夹下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "============================  **模型预测代码答题区域**  ============================\n",
    "<br>\n",
    "\n",
    "\n",
    "在下方的代码块中编写 **模型预测** 部分的代码，请勿在别的位置作答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "select": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def data_processing_and_feature_selecting(data_path): \n",
    "    \"\"\"\n",
    "    特征选择\n",
    "    :param  data_path: 数据集路径\n",
    "    :return: new_features,label: 经过预处理和特征选择后的特征数据、标签数据\n",
    "    \"\"\" \n",
    "    new_features,label = None, None\n",
    "    # -------------------------- 实现数据处理和特征选择部分代码 ----------------------------\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # 返回筛选后的数据\n",
    "    return new_features,label\n",
    "\n",
    "\n",
    "    \n",
    "# -------------------------- 请加载您最满意的模型 ---------------------------\n",
    "# 加载模型(请加载你认为的最佳模型)\n",
    "# 加载模型,加载请注意 model_path 是相对路径, 与当前文件同级。\n",
    "# 如果你的模型是在 results 文件夹下的 my_model.m 模型，则 model_path = 'results/my_model.m'\n",
    "model_path = None\n",
    "\n",
    "# 加载模型\n",
    "model = None\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def predict(new_features):\n",
    "    \"\"\"\n",
    "    加载模型和模型预测\n",
    "    :param  new_features : 测试数据，是 data_processing_and_feature_selecting 函数的返回值之一。\n",
    "    :return y_predict : 预测结果是标签值。\n",
    "    \"\"\"\n",
    "    # -------------------------- 实现模型预测部分的代码 ---------------------------\n",
    "    # 获取输入图片的类别\n",
    "    y_predict = None\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    # 返回图片的类别\n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "## 3.3 **测试提交函数示例**\n",
    "\n",
    "例：对数据不做任何预处理，进行特征整合，并训练得到模型`my_model.m`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "def data_processing_and_feature_selecting(data_path): \n",
    "    \"\"\"\n",
    "    特征选择\n",
    "    :param  data_path: 数据集路径\n",
    "    :return: new_features,label: 经过预处理和特征选择后的特征数据、类标数据\n",
    "    \"\"\" \n",
    "    \n",
    "     #导入医疗数据\n",
    "    data_xls = pd.ExcelFile(data_path)\n",
    "    data={}\n",
    "    #查看数据名称与大小\n",
    "    for name in data_xls.sheet_names:\n",
    "            df=data_xls.parse(sheetname=name,header=None)\n",
    "            data[name]=df\n",
    "    #获取数据\n",
    "    feature1_raw=data['Feature1']\n",
    "    feature2_raw=data['Feature2']\n",
    "    label=data['label']\n",
    "\n",
    "    # 整合得到新特征\n",
    "    features = pd.concat([feature1_raw,feature2_raw],axis=1)\n",
    "    \n",
    "    new_features = features\n",
    "\n",
    "    # 返回筛选后的数据\n",
    "    return new_features,label\n",
    "\n",
    "\n",
    "    \n",
    "# -------------------------- 请加载您最满意的模型 ---------------------------\n",
    "# 加载模型(请加载你认为的最佳模型)\n",
    "model_path = 'results/my_model.m'\n",
    "\n",
    "# 加载模型\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def predict(new_features):\n",
    "    \"\"\"\n",
    "    加载模型和模型预测\n",
    "    :param  new_features : 测试数据\n",
    "    :return y_predict : 预测结果\n",
    "    \"\"\"\n",
    "\n",
    "    y_predict = model.predict(new_features)\n",
    "\n",
    "    \n",
    "    # 返回图片的类别\n",
    "    return y_predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "nbTranslate": {
   "displayLangs": [
    "fr",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
